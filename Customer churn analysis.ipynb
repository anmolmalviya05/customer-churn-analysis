{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57ea8c1",
   "metadata": {},
   "source": [
    "# Telco Customer Churn Analysis\n",
    "\n",
    "### submitted to :- Mr. Upendra Singh\n",
    "### submitted by :- Anmol Malviya\n",
    "### Roll No. :- DS5B2106\n",
    "\n",
    "### Department :- School of Data Science and forecasting\n",
    "### Batch           :- 2021-23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f8767",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5225fd5",
   "metadata": {},
   "source": [
    "Predicting customer churn is critical for telecommunication companies to be able to effectively retain customers. It is more costly to acquire new customers than to retain existing ones. For this reason, large telecommunications corporations are seeking to develop models to predict which customers are more likely to change and take actions accordingly.\n",
    "\n",
    "In this project, we build a model to predict how likely a customer will churn by analyzing its characteristics: \n",
    "\n",
    "(1) demographic information\n",
    "\n",
    "(2) account information\n",
    "\n",
    "(3) services information.\n",
    "\n",
    "The objective is to obtain a data-driven solution that will allow us to reduce churn rates and, as a consequence, to increase customer satisfaction and corporation revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46839b4b",
   "metadata": {},
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7656c10",
   "metadata": {},
   "source": [
    "The data set used in this project is available on Kaggle and contains nineteen columns (independent variables) that indicate the of the clients of a fictional telecommunications corporation. The Churn column (response variable) indicates whether the customer departed within the last month or not. The class No includes the clients that did not leave the company last month, while the class Yes contains the clients that decided to terminate their relations with the company. The objective of the analysis is to obtain the relation between the customer’s characteristics and the churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03567c36",
   "metadata": {},
   "source": [
    "### Importing libraries and Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b52d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.ticker as mtick  \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f93fb0",
   "metadata": {},
   "source": [
    "# Data reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b66df",
   "metadata": {},
   "source": [
    "The first step of the analysis consists of reading and storing the data in a Pandas data frame using the pandas.read_csv function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abd8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco = pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcebb388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
       "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
       "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
       "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
       "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_telco.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a646e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column :customerID - Unique Values: ['7590-VHVEG' '5575-GNVDE' '3668-QPYBK' ... '4801-JZAZL' '8361-LTMKD'\n",
      " '3186-AJIEK']\n",
      "Column :gender - Unique Values: ['Female' 'Male']\n",
      "Column :SeniorCitizen - Unique Values: [0 1]\n",
      "Column :Partner - Unique Values: ['Yes' 'No']\n",
      "Column :Dependents - Unique Values: ['No' 'Yes']\n",
      "Column :tenure - Unique Values: [ 1 34  2 45  8 22 10 28 62 13 16 58 49 25 69 52 71 21 12 30 47 72 17 27\n",
      "  5 46 11 70 63 43 15 60 18 66  9  3 31 50 64 56  7 42 35 48 29 65 38 68\n",
      " 32 55 37 36 41  6  4 33 67 23 57 61 14 20 53 40 59 24 44 19 54 51 26  0\n",
      " 39]\n",
      "Column :PhoneService - Unique Values: ['No' 'Yes']\n",
      "Column :MultipleLines - Unique Values: ['No phone service' 'No' 'Yes']\n",
      "Column :InternetService - Unique Values: ['DSL' 'Fiber optic' 'No']\n",
      "Column :OnlineSecurity - Unique Values: ['No' 'Yes' 'No internet service']\n",
      "Column :OnlineBackup - Unique Values: ['Yes' 'No' 'No internet service']\n",
      "Column :DeviceProtection - Unique Values: ['No' 'Yes' 'No internet service']\n",
      "Column :TechSupport - Unique Values: ['No' 'Yes' 'No internet service']\n",
      "Column :StreamingTV - Unique Values: ['No' 'Yes' 'No internet service']\n",
      "Column :StreamingMovies - Unique Values: ['No' 'Yes' 'No internet service']\n",
      "Column :Contract - Unique Values: ['Month-to-month' 'One year' 'Two year']\n",
      "Column :PaperlessBilling - Unique Values: ['Yes' 'No']\n",
      "Column :PaymentMethod - Unique Values: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "Column :MonthlyCharges - Unique Values: [29.85 56.95 53.85 ... 63.1  44.2  78.7 ]\n",
      "Column :TotalCharges - Unique Values: ['29.85' '1889.5' '108.15' ... '346.45' '306.6' '6844.5']\n",
      "Column :Churn - Unique Values: ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "#check unique values of each column\n",
    "for column in df_telco.columns:\n",
    "    print('Column :{} - Unique Values: {}'.format(column,df_telco[column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4873d5",
   "metadata": {},
   "source": [
    "As shown above, the data set contains 19 independent variables, which can be classified into 3 groups:\n",
    "\n",
    "(1) Demographic Information\n",
    "\n",
    "gender: Whether the client is a female or a male (Female, Male).\n",
    "SeniorCitizen: Whether the client is a senior citizen or not ( 0, 1).\n",
    "Partner: Whether the client has a partner or not (Yes, No).\n",
    "Dependents: Whether the client has dependents or not (Yes, No)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49cd3de",
   "metadata": {},
   "source": [
    "(2) Customer Account Information\n",
    "\n",
    "tenure: Number of months the customer has stayed with the company (Multiple different numeric values).\n",
    "Contract: Indicates the customer’s current contract type (Month-to-Month, One year, Two year).\n",
    "PaperlessBilling: Whether the client has paperless billing or not (Yes, No).\n",
    "PaymentMethod: The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit Card (automatic)).\n",
    "MontlyCharges: The amount charged to the customer monthly (Multiple different numeric values).\n",
    "TotalCharges: The total amount charged to the customer (Multiple different numeric values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7246c",
   "metadata": {},
   "source": [
    "(3) Services Information\n",
    "\n",
    "PhoneService: Whether the client has a phone service or not (Yes, No).\n",
    "MultipleLines: Whether the client has multiple lines or not (No phone service, No, Yes).\n",
    "InternetServices: Whether the client is subscribed to Internet service with the company (DSL, Fiber optic, No)\n",
    "OnlineSecurity: Whether the client has online security or not (No internet service, No, Yes).\n",
    "OnlineBackup: Whether the client has online backup or not (No internet service, No, Yes).\n",
    "DeviceProtection: Whether the client has device protection or not (No internet service, No, Yes).\n",
    "TechSupport: Whether the client has tech support or not (No internet service, No, Yes).\n",
    "StreamingTV: Whether the client has streaming TV or not (No internet service, No, Yes).\n",
    "StreamingMovies: Whether the client has streaming movies or not (No internet service, No, Yes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8bd76a",
   "metadata": {},
   "source": [
    "###  Exploratory Data Analysis and Data Cleaning\n",
    "Exploratory data analysis consists of analyzing the main characteristics of a data set usually by means of visualization methods and summary statistics. The objective is to understand the data, discover patterns and anomalies, and check assumptions before performing further evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e068b",
   "metadata": {},
   "source": [
    "#### Missing values and data types\n",
    "At the beginning of EDA, we want to know as much information as possible about the data, this is when the pandas.DataFrame.info method comes in handy. This method prints a concise summary of the data frame, including the column names and their data types, the number of non-null values, and the amount of memory used by the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08f6662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#summary of dataset\n",
    "df_telco.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be8444",
   "metadata": {},
   "source": [
    "As shown above, the data set contains 7043 observations and 21 columns. Apparently, there are no null values on the data set; however, we observe that the column TotalCharges was wrongly detected as an object. This column represents the total amount charged to the customer and it is, therefore, a numeric variable. For further analysis, we need to transform this column into a numeric data type. To do so, we can use the pd.to_numeric function. By default, this function raises an exception when it sees non-numeric data; however, we can use the argument errors='coerce' to skip those cases and replace them with a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c2dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco['TotalCharges'] = pd.to_numeric(df_telco['TotalCharges'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f9f07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4472-LVYGI</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>52.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>3115-CZMZD</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>5709-LVOEQ</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>80.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>4367-NUYAO</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1371-DWPAZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>56.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>7644-OMVMY</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>3213-VVOLG</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>2520-SGTTA</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>2923-ARZLG</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>4075-WKNIU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>73.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>2775-SEFEE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>61.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n",
       "488   4472-LVYGI  Female              0     Yes        Yes       0   \n",
       "753   3115-CZMZD    Male              0      No        Yes       0   \n",
       "936   5709-LVOEQ  Female              0     Yes        Yes       0   \n",
       "1082  4367-NUYAO    Male              0     Yes        Yes       0   \n",
       "1340  1371-DWPAZ  Female              0     Yes        Yes       0   \n",
       "3331  7644-OMVMY    Male              0     Yes        Yes       0   \n",
       "3826  3213-VVOLG    Male              0     Yes        Yes       0   \n",
       "4380  2520-SGTTA  Female              0     Yes        Yes       0   \n",
       "5218  2923-ARZLG    Male              0     Yes        Yes       0   \n",
       "6670  4075-WKNIU  Female              0     Yes        Yes       0   \n",
       "6754  2775-SEFEE    Male              0      No        Yes       0   \n",
       "\n",
       "     PhoneService     MultipleLines InternetService       OnlineSecurity  ...  \\\n",
       "488            No  No phone service             DSL                  Yes  ...   \n",
       "753           Yes                No              No  No internet service  ...   \n",
       "936           Yes                No             DSL                  Yes  ...   \n",
       "1082          Yes               Yes              No  No internet service  ...   \n",
       "1340           No  No phone service             DSL                  Yes  ...   \n",
       "3331          Yes                No              No  No internet service  ...   \n",
       "3826          Yes               Yes              No  No internet service  ...   \n",
       "4380          Yes                No              No  No internet service  ...   \n",
       "5218          Yes                No              No  No internet service  ...   \n",
       "6670          Yes               Yes             DSL                   No  ...   \n",
       "6754          Yes               Yes             DSL                  Yes  ...   \n",
       "\n",
       "         DeviceProtection          TechSupport          StreamingTV  \\\n",
       "488                   Yes                  Yes                  Yes   \n",
       "753   No internet service  No internet service  No internet service   \n",
       "936                   Yes                   No                  Yes   \n",
       "1082  No internet service  No internet service  No internet service   \n",
       "1340                  Yes                  Yes                  Yes   \n",
       "3331  No internet service  No internet service  No internet service   \n",
       "3826  No internet service  No internet service  No internet service   \n",
       "4380  No internet service  No internet service  No internet service   \n",
       "5218  No internet service  No internet service  No internet service   \n",
       "6670                  Yes                  Yes                  Yes   \n",
       "6754                   No                  Yes                   No   \n",
       "\n",
       "          StreamingMovies  Contract PaperlessBilling  \\\n",
       "488                    No  Two year              Yes   \n",
       "753   No internet service  Two year               No   \n",
       "936                   Yes  Two year               No   \n",
       "1082  No internet service  Two year               No   \n",
       "1340                   No  Two year               No   \n",
       "3331  No internet service  Two year               No   \n",
       "3826  No internet service  Two year               No   \n",
       "4380  No internet service  Two year               No   \n",
       "5218  No internet service  One year              Yes   \n",
       "6670                   No  Two year               No   \n",
       "6754                   No  Two year              Yes   \n",
       "\n",
       "                  PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "488   Bank transfer (automatic)          52.55           NaN     No  \n",
       "753                Mailed check          20.25           NaN     No  \n",
       "936                Mailed check          80.85           NaN     No  \n",
       "1082               Mailed check          25.75           NaN     No  \n",
       "1340    Credit card (automatic)          56.05           NaN     No  \n",
       "3331               Mailed check          19.85           NaN     No  \n",
       "3826               Mailed check          25.35           NaN     No  \n",
       "4380               Mailed check          20.00           NaN     No  \n",
       "5218               Mailed check          19.70           NaN     No  \n",
       "6670               Mailed check          73.35           NaN     No  \n",
       "6754  Bank transfer (automatic)          61.90           NaN     No  \n",
       "\n",
       "[11 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_telco[df_telco['TotalCharges'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd1cf2",
   "metadata": {},
   "source": [
    "  These observations have also a tenure of 0, even though MontlyCharges is not null for these entries. This information appeared to be contradictory, and therefore, we decide to remove those observations from the data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba0bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226b0d8",
   "metadata": {},
   "source": [
    "### Remove customerID column\n",
    "The customerID column is useless to explain whether not the customer will churn. Therefore, we drop this column from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813a6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop the customerID column from the dataset\n",
    "df_telco.drop(columns='customerID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644457b",
   "metadata": {},
   "source": [
    "### Payment method denominations\n",
    "As shown below, some payment method denominations contain in parenthesis the word automatic. These denominations are too long to be used as tick labels in further visualizations. Therefore, we remove this clarification in parenthesis from the entries of the PaymentMethod column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e92b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Electronic check', 'Mailed check', 'Bank transfer (automatic)',\n",
       "       'Credit card (automatic)'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique elements of the PaymentMethod column\n",
    "df_telco.PaymentMethod.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ded6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove (automatic) from payment method names\n",
    "df_telco['PaymentMethod'] = df_telco['PaymentMethod'].str.replace(' (automatic)', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4e1a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique elements of the PaymentMethod column after the modification \n",
    "df_telco.PaymentMethod.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebdd54",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4f1b6",
   "metadata": {},
   "source": [
    "Feature engineering is the process of extracting features from the data and transforming them into a format that is suitable for the machine learning model. In this project, we need to transform both numerical and categorical variables. Most machine learning algorithms require numerical values; therefore, all categorical attributes available in the dataset should be encoded into numerical labels before training the model. In addition, we need to transform numeric columns into a common scale. This will prevent that the columns with large values dominate the learning process. The techniques implemented in this project are described in more detail below. All transformations are implemented using only Pandas; however, we also provide an alternative implementation using Scikit-Learn. As you can see, there are multiple ways to solve the same problem 😃.\n",
    "\n",
    "### No modification\n",
    "The SeniorCitizen column is already a binary column and should not be modified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe6fa4",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "Label encoding is used to replace categorical values with numerical values. This encoding replaces every category with a numerical label. In this project, we use label encoding with the following binary variables: (1) gender, (2) Partner, (3) Dependents, (4)PaperlessBilling, (5)PhoneService , and (6)Churn ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c49ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco_transformed = df_telco.copy()\n",
    "\n",
    "# label encoding (binary variables)\n",
    "label_encoding_columns = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService', 'Churn']\n",
    "\n",
    "# encode categorical binary features using label encoding\n",
    "for column in label_encoding_columns:\n",
    "    if column == 'gender':\n",
    "        df_telco_transformed[column] = df_telco_transformed[column].map({'Female': 1, 'Male': 0})\n",
    "    else: \n",
    "        df_telco_transformed[column] = df_telco_transformed[column].map({'Yes': 1, 'No': 0}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5ca21",
   "metadata": {},
   "source": [
    "# One-Hot Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44831808",
   "metadata": {},
   "source": [
    "One-hot encoding creates a new binary column for each level of the categorical variable. The new column contains zeros and ones indicating the absence or presence of the category in the data. In this project, we apply one-hot encoding to the following categorical variables: (1) Contract, (2) PaymentMethod, (3) MultipleLines, (4) InternetServices, (5) OnlineSecurity, (6) OnlineBackup, (7) DeviceProtection, (8) TechSupport, (9) StreamingTV, and (10)StreamingMovies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "592e62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding (categorical variables with more than two levels)\n",
    "one_hot_encoding_columns = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                            'TechSupport', 'StreamingTV',  'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "\n",
    "# encode categorical variables with more than two levels using one-hot encoding\n",
    "df_telco_transformed = pd.get_dummies(df_telco_transformed, columns = one_hot_encoding_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7bdbc9",
   "metadata": {},
   "source": [
    "The main drawback of this encoding is the significant increase in the dimensionality of the dataset (curse of dimensionality); therefore, this method should be avoided when the categorical column has a large number of unique values.\n",
    "\n",
    "### Normalization\n",
    "Data Normalization is a common practice in machine learning which consists of transforming numeric columns to a common scale. In machine learning, some feature values differ from others multiple times. The features with higher values will dominate the learning process; however, it does not mean those variables are more important to predict the target. Data normalization transforms multiscaled data to the same scale. After normalization, all variables have a similar influence on the model, improving the stability and performance of the learning algorithm.\n",
    "\n",
    "There are multiple normalization techniques in statistics. In this project, we will use the min-max method to rescale the numeric columns (tenure, MontlyCharges, and TotalCharges) to a common scale. The min-max approach (often called normalization) rescales the feature to a fixed range of [0,1] by subtracting the minimum value of the feature and then dividing by the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dcfbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalization (numeric variables)\n",
    "min_max_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# scale numerical variables using min max scaler\n",
    "for column in min_max_columns:\n",
    "        # minimum value of the column\n",
    "        min_column = df_telco_transformed[column].min()\n",
    "        # maximum value of the column\n",
    "        max_column = df_telco_transformed[column].max()\n",
    "        # min max scaler\n",
    "        df_telco_transformed[column] = (df_telco_transformed[column] - min_column) / (max_column - min_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e23cab",
   "metadata": {},
   "source": [
    "### Setting a baseline\n",
    "In machine learning, we often use a simple classifier called baseline to evaluate the performance of a model. In this classification problem, the rate of customers that did not churn (most frequent class) can be used as a baseline to evaluate the quality of the models generated. These models should outperform the baseline capabilities to be considered for future predictions.\n",
    "\n",
    "### Splitting the data in training and testing sets\n",
    "The first step when building a model is to split the data into two groups, which are typically referred to as training and testing sets. The training set is used by the machine learning algorithm to build the model. The test set contains samples that are not part of the learning process and is used to evaluate the model’s performance. It is important to assess the quality of the model using unseen data to guarantee an objective evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297fa41",
   "metadata": {},
   "source": [
    "First, we create a variable X to store the independent attributes of the dataset. Additionally, we create a variable y to store only the target variable (Churn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d9f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
      "       'PhoneService', 'PaperlessBilling', 'MonthlyCharges', 'TotalCharges',\n",
      "       'MultipleLines_No', 'MultipleLines_No phone service',\n",
      "       'MultipleLines_Yes', 'InternetService_DSL',\n",
      "       'InternetService_Fiber optic', 'InternetService_No',\n",
      "       'OnlineSecurity_No', 'OnlineSecurity_No internet service',\n",
      "       'OnlineSecurity_Yes', 'OnlineBackup_No',\n",
      "       'OnlineBackup_No internet service', 'OnlineBackup_Yes',\n",
      "       'DeviceProtection_No', 'DeviceProtection_No internet service',\n",
      "       'DeviceProtection_Yes', 'TechSupport_No',\n",
      "       'TechSupport_No internet service', 'TechSupport_Yes', 'StreamingTV_No',\n",
      "       'StreamingTV_No internet service', 'StreamingTV_Yes',\n",
      "       'StreamingMovies_No', 'StreamingMovies_No internet service',\n",
      "       'StreamingMovies_Yes', 'Contract_Month-to-month', 'Contract_One year',\n",
      "       'Contract_Two year', 'PaymentMethod_Bank transfer',\n",
      "       'PaymentMethod_Credit card', 'PaymentMethod_Electronic check',\n",
      "       'PaymentMethod_Mailed check'],\n",
      "      dtype='object')\n",
      "Churn\n"
     ]
    }
   ],
   "source": [
    "# select independent variables\n",
    "X = df_telco_transformed.drop(columns='Churn')\n",
    "\n",
    "# select dependent variables\n",
    "y = df_telco_transformed.loc[:, 'Churn']\n",
    "\n",
    "# prove that the variables were selected correctly\n",
    "print(X.columns)\n",
    "\n",
    "# prove that the variables were selected correctly\n",
    "print(y.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc7e5d",
   "metadata": {},
   "source": [
    "Then, we can use the train_test_split function from the sklearn.model_selection package to create both the training and testing sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca6cf9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd01343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d02193",
   "metadata": {},
   "source": [
    "### Assessing multiple algorithms\n",
    "Algorithm selection is a key challenge in any machine learning project since there is not an algorithm that is the best across all projects. Generally, we need to evaluate a set of potential candidates and select for further evaluation those that provide better performance.\n",
    "\n",
    "In this project, we compare 6 different algorithms, all of them already implemented in Scikit-Learn.\n",
    "\n",
    "Dummy classifier (baseline)\n",
    "K Nearest Neighbours\n",
    "Logistic Regression\n",
    "Support Vector Machines\n",
    "Random Forest\n",
    "Gradiente Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c74db",
   "metadata": {},
   "source": [
    "As shown below, all models outperform the dummy classifier model in terms of prediction accuracy. Therefore, we can affirm that machine learning is applicable to our problem because we observe an improvement over the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c9dca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa93701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(seed=2):\n",
    "    '''\n",
    "    Create a list of machine learning models.\n",
    "            Parameters:\n",
    "                    seed (integer): random seed of the models\n",
    "            Returns:\n",
    "                    models (list): list containing the models\n",
    "    '''\n",
    "\n",
    "    models = []\n",
    "    models.append(('dummy_classifier', DummyClassifier(random_state=seed, strategy='most_frequent')))\n",
    "    models.append(('k_nearest_neighbors', KNeighborsClassifier()))\n",
    "    models.append(('logistic_regression', LogisticRegression(random_state=seed)))\n",
    "    models.append(('support_vector_machines', SVC(random_state=seed)))\n",
    "    models.append(('random_forest', RandomForestClassifier(random_state=seed)))\n",
    "    models.append(('gradient_boosting', GradientBoostingClassifier(random_state=seed)))\n",
    "    \n",
    "    return models\n",
    "\n",
    "# create a list with all the algorithms we are going to assess\n",
    "models = create_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b2395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c8bd0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: dummy_classifier, Accuracy: 0.745164960182025)\n",
      "Classifier: k_nearest_neighbors, Accuracy: 0.7531285551763367)\n",
      "Classifier: logistic_regression, Accuracy: 0.7923777019340159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anmol\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: support_vector_machines, Accuracy: 0.7878270762229806)\n",
      "Classifier: random_forest, Accuracy: 0.7713310580204779)\n",
      "Classifier: gradient_boosting, Accuracy: 0.7963594994311718)\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of each model using default hyperparameters\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    # fit the model with the training data\n",
    "    model.fit(X_train, y_train).predict(X_test)\n",
    "    # make predictions with the testing data\n",
    "    predictions = model.predict(X_test)\n",
    "    # calculate accuracy \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    # append the model name and the accuracy to the lists\n",
    "    results.append(accuracy)\n",
    "    names.append(name)\n",
    "    # print classifier accuracy\n",
    "    print('Classifier: {}, Accuracy: {})'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a800f",
   "metadata": {},
   "source": [
    "It is important to bear in mind that we have trained all the algorithms using the default hyperparameters. The accuracy of many machine learning algorithms is highly sensitive to the hyperparameters chosen for training the model. A more in-depth analysis will include an evaluation of a wider range of hyperparameters (not only default values) before choosing a model (or models) for hyperparameter tuning. Nonetheless, this is out of the scope of this article. In this example, we will only further evaluate the model that presents higher accuracy using the default hyperparameters. As shown above, this corresponds to the gradient boosting model which shows an accuracy of nearly 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010dd029",
   "metadata": {},
   "source": [
    "### Algorithm selected: Gradient Boosting\n",
    "Gradient Boosting is a very popular machine learning ensemble method based on a sequential training of multiple models to make predictions. In Gradient Boosting, first, you make a model using a random sample of your original data. After fitting the model, you make predictions and compute the residuals of your model. The residuals are the difference between the actual values and the predictions of the model. Then, you train a new tree based on the residuals of the previous tree, calculating again the residuals of this new model. We repeat this process until we reach a threshold (residual close to 0), meaning there is a very low difference between the actual and predicted values. Finally, you take a sum of all model forecasts (prediction of the data and predictions of the error) to make a final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a4229",
   "metadata": {},
   "source": [
    "We can easily build a gradient boosting classifier with Scikit-Learn using the GradientBoostingClassifier class from the sklearn.ensemble module. After creating the model, we need to train it (using the .fit method) and test its performance by comparing the predictions (.predict method) with the actual class values, as you can see in the code above.\n",
    "\n",
    "the GradientBoostingClassifier has multiple hyperparameters; some of them are listed below:\n",
    "\n",
    "learning_rate: the contribution of each tree to the final prediction.\n",
    "\n",
    "n_estimators: the number of decision trees to perform (boosting stages).\n",
    "\n",
    "max_depth: the maximum depth of the individual regression estimators.\n",
    "\n",
    "max_features: the number of features to consider when looking for the best split.\n",
    "\n",
    "\n",
    "min_samples_split: the minimum number of samples required to split an internal node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272de12",
   "metadata": {},
   "source": [
    "The next step consists of finding the combination of hyperparameters that leads to the best classification of our data. This process is called hyperparameter tuning.\n",
    "\n",
    "### Hyperparameter tuning\n",
    "Thus far we have split our data into a training set for learning the parameters of the model, and a testing set for evaluating its performance. The next step in the machine learning process is to perform hyperparameter tuning. The selection of hyperparameters consists of testing the performance of the model against different combinations of hyperparameters, selecting those that perform best according to a chosen metric and a validation method.\n",
    "\n",
    "For hyperparameter tuning, we need to split our training data again into a set for training and a set for testing the hyperparameters (often called validation set). It is a very common practice to use k-fold cross-validation for hyperparameter tuning. The training set is divided again into k equal-sized samples, 1 sample is used for testing and the remaining k-1 samples are used for training the model, repeating the process k times. Then, the k evaluation metrics (in this case the accuracy) are averaged to produce a single estimator.\n",
    "\n",
    "It is important to stress that the validation set is used for hyperparameter selection and not for evaluating the final performance of our model, as shown in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2efbe",
   "metadata": {},
   "source": [
    "There are multiple techniques to find the best hyperparameters for a model. The most popular methods are (1) grid search, (2) random search, and (3) bayesian optimization. Grid search test all combinations of hyperparameters and select the best performing one. It is a really time-consuming method, particularly when the number of hyperparameters and values to try are really high.\n",
    "\n",
    "In random search, you specify a grid of hyperparameters, and random combinations are selected where each combination of hyperparameters has an equal chance of being sampled. We do not analyze all combinations of hyperparameters, but only random samples of those combinations. This approach is much more computationally efficient than trying all combinations; however, it also has some disadvantages. The main drawback of random search is that not all areas of the grid are evenly covered, especially when the number of combinations selected from the grid is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8fb15",
   "metadata": {},
   "source": [
    "We can implement random search in Scikit-learn using the RandomSearchCV class from the sklearn.model_selection package.\n",
    "\n",
    "First of all, we specify the grid of hyperparameter values using a dictionary (grid_parameters) where the keys represent the hyperparameters and the values are the set of options we want to evaluate. Then, we define the RandomizedSearchCV object for trying different random combinations from this grid. The number of hyperparameter combinations that are sampled is defined in the n_iter parameter. Naturally, increasing n_iter will lead in most cases to more accurate results, since more combinations are sampled; however, on many occasions, the improvement in performance won’t be significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e2aa9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f4f2100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 120, 'min_samples_split': 3, 'max_features': 'sqrt', 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid\n",
    "grid_parameters = {'n_estimators': [80, 90, 100, 110, 115, 120],\n",
    "                   'max_depth': [3, 4, 5, 6],\n",
    "                   'max_features': [None, 'auto', 'sqrt', 'log2'], \n",
    "                   'min_samples_split': [2, 3, 4, 5]}\n",
    "\n",
    "\n",
    "# define the RandomizedSearchCV class for trying different parameter combinations\n",
    "random_search = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                   param_distributions=grid_parameters,\n",
    "                                   cv=5,\n",
    "                                   n_iter=150,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# fitting the model for random search \n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae76110",
   "metadata": {},
   "source": [
    "After fitting the grid object, we can obtain the best hyperparameters using best_params_attribute. As you can above, the best hyperparameters are: {‘n_estimators’: 90, ‘min_samples_split’: 3, ‘max_features’: ‘log2’, ‘max_depth’: 3}.\n",
    "\n",
    "### Performace of the model\n",
    "The last step of the machine learning process is to check the performance of the model (best hyperparameters ) by using the confusion matrix and some evaluation metrics.\n",
    "\n",
    "Confusion matrix\n",
    "The confusion matrix, also known as the error matrix, is used to evaluate the performance of a machine learning model by examining the number of observations that are correctly and incorrectly classified. Each column of the matrix contains the predicted classes while each row represents the actual classes or vice versa. In a perfect classification, the confusion matrix will be all zeros except for the diagonal. All the elements out of the main diagonal represent misclassifications. It is important to bear in mind that the confusion matrix allows us to observe patterns of misclassification (which classes and to which extend they were incorrectly classified).\n",
    "\n",
    "In binary classification problems, the confusion matrix is a 2-by-2 matrix composed of 4 elements:\n",
    "\n",
    "TP (True Positive): number of patients with spine problems that are correctly classified as sick.\n",
    "TN (True Negative): number of patients without pathologies who are correctly classified as healthy.\n",
    "FP (False Positive): number of healthy patients that are wrongly classified as sick.\n",
    "FN (False Negative): number of patients with spine diseases that are misclassified as healthy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64573b0",
   "metadata": {},
   "source": [
    "Now that the model is trained, it is time to evaluate its performance using the testing set. First, we use the previous model (gradient boosting classifier with best hyperparameters) to predict the class labels of the testing data (with the predict method). Then, we construct the confusion matrix using the confusion_matrix function from the sklearn.metrics package to check which observations were properly classified. The output is a NumPy array where the rows represent the true values and the columns the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "160c87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0d50fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1152,  158],\n",
       "       [ 201,  247]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the predictions\n",
    "random_search_predictions = random_search.predict(X_test)\n",
    "\n",
    "# construct the confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, random_search_predictions)\n",
    "\n",
    "# visualize the confusion matrix\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68a853",
   "metadata": {},
   "source": [
    "As shown above, 1402 observations of the testing data were correctly classified by the model (1154 true negatives and 248 true positives). On the contrary, we can observe 356 misclassifications (156 false positives and 200 false negatives).\n",
    "\n",
    "Evaluation metrics\n",
    "Evaluating the quality of the model is a fundamental part of the machine learning process. The most used performance evaluation metrics are calculated based on the elements of the confusion matrix.\n",
    "\n",
    "Accuracy: It represents the proportion of predictions that were correctly classified. Accuracy is the most commonly used evaluation metric; however, it is important to bear in mind that accuracy can be misleading when working with imbalanced datasets.\n",
    "Sensitivity: It represents the proportion of positive samples (diseased patients) that are identified as such.\n",
    "    Specificity: It represents the proportion of negative samples (healthy patients) that are identified as such.\n",
    "        Precision: It represents the proportion of positive predictions that are actually correct.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c41732",
   "metadata": {},
   "source": [
    "We can calculate the evaluation metrics manually using the numbers of the confusion matrix. Alternatively, Scikit-learn has already implemented the function classification_report that provides a summary of the key evaluation metrics. The classification report contains the precision, sensitivity, f1-score, and support (number of samples) achieved for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9788aae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      1310\n",
      "           1       0.61      0.55      0.58       448\n",
      "\n",
      "    accuracy                           0.80      1758\n",
      "   macro avg       0.73      0.72      0.72      1758\n",
      "weighted avg       0.79      0.80      0.79      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, random_search_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00cff69",
   "metadata": {},
   "source": [
    "As shown above, we obtain a sensitivity of 0.55 (248/(200+248)) and a specificity of 0.88 (1154/(1154+156)). The model obtained predicts more accurately customers that do not churn. This should not surprise us at all, since gradient boosting classifiers are usually biased toward the classes with more observations.\n",
    "\n",
    "As you may have noticed, the previous summary does not contain the accuracy of the classification. However, this can be easily calculated using the function accuracy_score from the metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeac0b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957906712172924"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the accuracy of the model\n",
    "accuracy_score(y_test, random_search_predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cd7a7",
   "metadata": {},
   "source": [
    "As you can observe, hyperparameter tuning has barely increased the accuracy of the model.\n",
    "\n",
    "### Drawing conclusions — Summary\n",
    "In this post, we have walked through a complete end-to-end machine learning project using the Telco customer Churn dataset. We started by cleaning the data and analyzing. Then, to be able to build a machine learning model, we transformed the categorical data into numeric variables (feature engineering). After transforming the data, we tried 6 different machine learning algorithms using default parameters. Finally, we tuned the hyperparameters of the Gradient Boosting Classifier (best performance model) for model optimization, obtaining an accuracy of nearly 80% (close to 6% higher than the baseline).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee21658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ccd81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
